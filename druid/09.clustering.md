# Clustering

Druid는 확장성있고 fault-tolerant한 클러스터로 설계되었다.

## Hadware

**Coordinator와 Overlord**는 metadata를 핸들링하고 조정하기위해 단일 서버에 같이 배치하는 것이 좋다.

AWS m3.xlarge를 추천함

**Historicals, MiddleManagers**는 실제 데이터를 처리하기 위해 같이 배치한느 것이 좋다. **CPU, RAM, SSDs**

AWS r3.2xlarge를 추천함

**Brokers**는 쿼리를 받고 다른 클러스터에 보내주는데, in-memory 쿼리 캐시를 위해 **CPU와 RAM**이 좋아야함

AWS r3.2xlarge를 추천함

브로커가 있는 서버에 UI 대시보드(superset, metabase...) 나 다른 쿼리 라이브러리를 설치하는 것이 좋음

## OS

너가 좋아하는 Linux 배포판을 사용하면됨. 단지 필요한 것은 **Java 8 이상의 버전**

## Deep Storage

HDFS나 S3를 사용하는 것을 추천

`conf/druid/_common/common.runtime.properties`파일에 `druid.storage.type` 프로퍼티의 값으로 설정할 수 있음

#### S3 설정

```properties
# conf/druid/_common/common.runtime.properties

druid.extensions.loadList=["druid-s3-extensions"]

druid.storage.type=s3
druid.storage.bucket=your-bucket
druid.storage.baseKey=druid/segments
druid.s3.accessKey=...
druid.s3.secretKey=...

druid.indexer.logs.type=s3
druid.indexer.logs.s3Bucket=your-bucket
druid.indexer.logs.s3Prefix=druid/indexing-logs
```

#### HDFS 설정

```properties
druid.extensions.loadList=["druid-hdfs-storage"]

druid.storage.type=hdfs
druid.storage.storageDirectory=/druid/segments

druid.indexer.logs.type=hdfs
druid.indexer.logs.directory=/druid/indexing-logs
```

그리고 `core-site.xml`, `hdfs-site.xml`, `yarn-site.xml`, `mapred-site.xml` 이 설정 파일들을 classpath에 넣어줘야함. 보통 `conf/druid/_common/` 이 아래에 넣어서 사용함.

## Tranquility(optional)

Realtime을 지원하려면 Tranquility를 사용해서 하는 편이 매우 간편함

## Hadoop(optional)

Hadoop Cluster로 부터 데이터를 로드할 경우 Hadoop관련 설정을 넣어 주어야함

```properties
# conf/middleManager/runtime.properties

druid.indexer.task.hadoopWorkingPath=/tmp/druid-indexing
```

`core-site.xml`, `hdfs-site.xml`, `yarn-site.xml`, `mapred-site.xml` 이 설정 파일들을 classpath에 넣어줘야함. 보통 `conf/druid/_common/` 이 아래에 넣어서 사용함.

Hadoop에서 데이터를 로드하기 위해 HDFS가 꼭 필요한 것은 아님. 예를 들어 **AWS에서 클러스터를 운용중이라면, Deep Storage를 S3로 사용하고 ElasticMapReduce를 사용하는 것도 좋은 방법.**

## Configure addresses for Druid coordination

```properties
# conf/druid/_common/common.runtime.properties

druid.zk.service.host=zk.service.host

druid.metadata.storage.connector.connectURI=...
druid.metadata.storage.connector.host=...
```

Production에서는  `Coordinator`와 `Overlord`가 각각 실행되고 있는 2개의 서버를 두는 것을 추천함. 

그리고 `Zookeeper`와 `MetaData Store`는 각각 분리해서 사용하는 것을 추천함.

## Open ports

- 1527 (Derby, 하지만 metadata store를 MySQL이나 PostgreSQL로 사용한다면 필요 없음)
- 2181 (ZooKeeper, Zookeep 클러스터를 분리한다면 필요 없음)
- 8081 (Coordinator)
- 8082 (Broker)
- 8083 (Historical)
- 8084 (Standalone Realtime, if used)
- 8088 (Router, if used)
- 8090 (Overlord)
- 8091, 8100–8199 (Druid Middle Manager, `druid.worker.capacity` 값을 조정해서 더 늘릴 수 있음)
- 8200 (Tranquility Server, if used)
